**Title:** Travel Cost & Package Recommendation Systems

**Goal:** 
- We are going to recommend the top 5 Packages according to the User input.
**Table of Contents**<a id = ToC>
- 0. [Data Collection](#DC)
- 1. [Data Validation](#DV)
       
- 2. [Exploratory Data Analysis](#EDA)
- 3. [Missing Values & Outliers Handling](#MVOH)
    
- 4. [Predictive Modeling](#PM)
**0. Data Collection**<a id = DC>
    
[Back to ToC](#ToC)
 
* For this project , We had taken open source Dataset

    **DatasetRef:** Open Sources
**Data Info:**
- We are having 1,20,000 Packages with 15 factors

Column|Description
-----------|--------------
Package_ID|Unique identifier for each travel package.
From_City|Starting city of the traveler (source location).
Destination|Final destination or travel location.
Destination_Type|Type of place (e.g., Beach, Hill Station, Historical, Adventure, Wildlife).
Trip_Duration_Days|Total duration of the trip in days.
Budget_Range|Overall budget category — Low, Medium, or High.
Approx_Cost (₹)|Estimated total cost of the travel package in Indian Rupees.
Accommodation_Type|Type of stay offered — Hotel, Resort, Hostel, Homestay, Villa, etc.
Transport_Mode|Mode of travel between source and destination — Flight, Train, Bus, Car.
Meal_Plan|Type of meal inclusion — Breakfast Only, Half Board, Full Board, All Inclusive.
Activity_Count|Number of activities or experiences included in the package.
Activity_Types|Types of activities — Sightseeing, Trekking, Water Sports, Safari, etc.
Season|Suitable season or time of the year to visit the destination.
Package_Type|Category of package — Budget, Standard, Premium, Luxury, Deluxe. (Target column)
Recommended_For|Ideal traveler type — Couples, Family, Friends, Solo, Corporate Group, etc.
# Basic Libraries
import pandas as pd # type: ignore
import numpy as np # type: ignore

import warnings, time, json
warnings.filterwarnings("ignore")
- Reading the CSV File
data = pd.read_csv("Travel_Packages_200K.csv")
**Basic Checks**
data.head()
data.info()
**2. Data Validation**<a id = DV>
    
[Back to ToC](#ToC)
- Verification of each and every column Data and its Data Type.
- Removing any Abnormalities and Special Characters in the Data for smooth process of Analysis.
- Removing the duplicated columns.
#Taking a copy of original data, so that original data will be safe.
df =data.copy()
df.columns
#Writing a Python function with df methods to validate columns
def colvalidate(df, col):
    print(f"Column: {col}")
    print()
    print(f"Number of Unique Values in Column: {df[col].nunique()}")
    print()
    print("Unique Values:")
    if df[col].nunique()>=100:
        for indx in range(0, df[col].nunique(), 100):
            print(df[col].unique()[indx:indx+100])
            print()
    else:
        print(df[col].unique())
        print()
    print("Data Type of Column:", df[col].dtype)
    print()
**Validation Starts now**
- We will start Data Validation for each column in order.
**1.Package_ID**
- Because of all unique values, no need to perform validation.
**2.From_City**
colvalidate(df, 'From_City')
- Data and Data Type of this column is valid.
**3.Destination**
colvalidate(df, 'Destination')
- Data and Data Type of this column is valid.
**4.Destination_Type**
colvalidate(df, 'Destination_Type')
- Data and Data Type of this column is valid.
**5.Trip_Duration_Days**
colvalidate(df, 'Trip_Duration_Days')
- Data and Data Type of this column is valid.
**6.Budget_Range**
colvalidate(df, 'Budget_Range')
- Data and Data Type of this column is valid.
**7.Approx_Cost (₹)**
colvalidate(df, 'Approx_Cost (₹)')
- Data and Data Type of this column is valid.
**8.Accommodation_Type**
colvalidate(df, 'Accommodation_Type')
- Data and Data Type of this column is valid.
**9.Transport_Mode**
colvalidate(df, 'Transport_Mode')
- Data and Data Type of this column is valid.
**10.Meal_Plan**
colvalidate(df, 'Meal_Plan')
- Data and Data Type of this column is valid.
**11.Activity_Count**
colvalidate(df, 'Activity_Count')
- Data and Data Type of this column is valid.
**12.Activity_Types**
colvalidate(df, 'Activity_Types')
- Data and Data Type of this column is valid.
**13.Season**
colvalidate(df, 'Season')
- Data and Data Type of this column is valid.
**14.Package_Type**
colvalidate(df, 'Package_Type')
- Data and Data Type of this column is valid.
**15.Recommended_For**
colvalidate(df, 'Recommended_For')
- Data and Data Type of this column is valid.
**Duplicated Rows checking**
- To check the duplicated rows, first we need to convert all categorical columns in lower case letters.
for col in df.columns:
    if df[col].dtype == object:
        df[col] = df[col].str.lower()
#Checking for duplicates
df[df.duplicated()]
- No duplicates found.
**3.EDA(Exploratory Data Analysis)**<a id = EDA>
    
[Back to ToC](#ToC)
**To get Insights on this Data**
- We can use EDA Techniques
  - Uni-Variate Analysis(Study of Single column data)
  - Bi/Multi-Variate Analysis(Data Study between Two/More columns)
- Above techniques will use **Descriptive Statistics** & **Visualizations.**
- **Descriptive Statistics**
  - Stats measures are used to understand column data.
  - To start with Descriptive Stats, first we need to understand the Types of Variables/Columns in given data.
- **Visualizations**
  - Pictorial Representation of the Data.
**Descriptive Statistics/Visualizations**
**Types of Variables/Columns**
Variable/Column | Type
----------|-----------
Package_ID | CO
From_City | CN
Destination | CN
Destination_Type | CN
Trip_Duration_Days | ND
Budget_Range | CO
Approx_Cost (₹) | ND
Accommodation_Type | CO
Transport_Mode | CO
Meal_Plan | CO
Activity_Count | ND 
Activity_Types | CN
Season | CN
Package_Type | CO
Recommended_For | CN

**Note:**
- **CO** - Categorical Ordinal
- **CN** - Categorical Nominal
- **ND** - Numerical Discrete
- **NC** - Numerical Continuous
**Uni-Variate Analysis** - Study of Single Column Data

- Descriptive Stats Univariate measures,
  - Numeric
    - Discrete
      - round(Mean), round(Median), Mode, Five Number Summary, Std, Skewness, Kurtosis
    - Continuous
      - Mean, Median, Five Number Summary, Std, Skewness, Kurtosis
  - Categorical & Boolean
    - nunique
    - unique
    - FDT
    - Mode
  - Date Time
    - Start Date, End Date, Diff between Start & End Date
- Visualizations for Uni-Variate
  - Categorical: Comparission: Pie/Bar
  - Numerical: Distribution: Hist/Box/Density
# Modules for Visualizations
import seaborn as sns # type: ignore
import matplotlib.pyplot as plt # type: ignore
from scipy.stats import pearsonr # type: ignore
from scipy.stats import f_oneway # type: ignore
import plotly.express as px # type: ignore
**Taking Uni-Variate Descriptive Stats User defined Functions**
# Writing functions according to col type

# To Supress Scientific Notation of Values
pd.set_option('display.float_format', lambda x: '%.2f' % x) # for 2 float points

from simple_colors import * # type: ignore # for color print -> pip install simple_colors

############################ Numeric Continuous ############################
def ncstudy(df, col):
    print(green("#######################################################",['bold'])) # type: ignore
    print(green("Taken Numeric Continuous Column:",['bold']), black(col,['bold'])) # type: ignore
    print(green("#######################################################",['bold'])) # type: ignore
    print()
    print(cyan("Descriptive Stats:",['bold'])) # type: ignore
    print()
    print(blue("******** Measures of Central Tendancy ************", ['bold'])) # type: ignore
    print(magenta("Mean:",['bold']), round(df[col].mean(),2)) # type: ignore
    print(magenta("Median:",['bold']), df[col].median()) # type: ignore
    print(magenta("Mode:",['bold']), df[col].mode()[0]) # type: ignore # Taking first value
    print()
    print(blue("******** Measures of Dispersion ************",['bold'])) # type: ignore
    print(magenta("Range:",['bold']), df[col].max()-df[col].min()) # type: ignore
    print(magenta("Variance:",['bold']), round(df[col].var(),2)) # type: ignore
    print(magenta("Standard Deviation:",['bold']), round(df[col].std(),2)) # type: ignore
    print(magenta("Five Number Summary:",['bold'])) # type: ignore
    print(round(data[col].describe(),2)[['min','25%','50%','75%','max']])
    print()
    print(blue("******** Measures of Symmetry ************",['bold'])) # type: ignore
    print(magenta("Skewness:",['bold']), round(df[col].skew(),2)) # type: ignore
    print(magenta("Kurtosis:",['bold']), round(df[col].kurt(),2)) # type: ignore
    print()
    print(cyan("Visualization:",['bold'])) # type: ignore
    print()
    px.box(df[col], orientation='h', width=650, height=300).show()
    print()

############################## Numeric Discrete #################################
def ndstudy(df, col):
    print(green("#######################################################",['bold'])) # type: ignore
    print(green("Taken Numeric Discrete Column:",['bold']), black(col,['bold'])) # type: ignore
    print(green("#######################################################",['bold'])) # type: ignore
    print()
    print(cyan("Uni-Variate Descriptive Stats:",['bold'])) # type: ignore
    print()
    print("******** Measures of Central Tendancy ************")
    print(magenta("Mean:",['bold']), round(df[col].mean())) # type: ignore
    print(magenta("Median:",['bold']), round(df[col].median())) # type: ignore
    print(magenta("Mode:",['bold']), df[col].mode()[0]) # type: ignore # Taking first value
    print()
    print("******** Measures of Dispersion ************")
    print(magenta("Range:",['bold']), df[col].max()-df[col].min()) # type: ignore
    print(magenta("Variance:",['bold']), round(df[col].var())) # type: ignore
    print(magenta("Standard Deviation:",['bold']), round(df[col].std())) # type: ignore
    print(magenta("Five Number Summary:",['bold'])) # type: ignore
    print(round(data[col].describe())[['min','25%','50%','75%','max']])
    print()
    print("******** Measures of Symmetry ************")
    print(magenta("Skewness:",['bold']), round(df[col].skew(),2)) # type: ignore
    print(magenta("Kurtosis:",['bold']), round(df[col].kurt(),2)) # type: ignore
    print()
    print(cyan("Visualization:",['bold'])) # type: ignore
    print()
    px.box(df[col], orientation='h', width=650, height=300).show()
    print()

############################# Categorical #######################################
def catstudy(df, col):
    print(green("#######################################################",['bold'])) # type: ignore
    print(green("Taken Categorical Column:",['bold']), black(col,['bold'])) # type: ignore
    print(green("#######################################################",['bold'])) # type: ignore
    print()
    print(cyan("Uni-Variate Descriptive Stats:",['bold'])) # type: ignore
    print()
    print(magenta("Number of Categories/Classes in column:",['bold']), df[col].nunique()) # type: ignore
    print(magenta("Category Names:",['bold'])) # type: ignore
    print(df[col].unique())
    print()
    print(magenta("Value Counts (FD) of each Category:",['bold'])) # type: ignore
    print(df[col].value_counts())
    print()
    print(magenta("Value Counts of Each Class (FD) as Percentage:",['bold'])) # type: ignore
    print(round((df[col].value_counts()/len(df))*100,2))
    print()
    print(magenta("Mode:",['bold']), df[col].mode()[0]) # type: ignore
    print()
    print(cyan("Visualization:",['bold'])) # type: ignore
    print()        
    print(black("Top Catgeories:", ['bold'])) # type: ignore
    # Considering only top 10 categories for pie chart
    index = df[col].value_counts().sort_values(ascending=False)[0:10].index
    vals = df[col].value_counts().sort_values(ascending=False)[0:10].values
    fig = px.pie(names=index, values=vals, width=700, height=400)
    fig.update_traces(textposition='inside', textinfo='percent+label')
    fig.update_layout(showlegend=False)
    fig.show()
    print()
    
######################################## DateTime ######################################
def datestudy(df, col):
    print(green("#######################################################",['bold'])) # type: ignore
    print(green("Taken Date Column:",['bold']), black(col,['bold'])) # type: ignore
    print(green("#######################################################",['bold'])) # type: ignore
    print()
    print(cyan("Uni-Variate Descriptive Stats:",['bold'])) # type: ignore
    print()
    print(magenta("Start Date:",['bold']), df[col].min()) # type: ignore
    print(magenta("End Date:",['bold']), df[col].max()) # type: ignore
    print(magenta("Total Time Period (in Years):",['bold']), (df[col].max()-df[col].min())) # type: ignore
    print()
    print(cyan("Visualization:",['bold'])) # type: ignore
    print()
    index = df[col].value_counts().index
    vals = df[col].value_counts().values
    px.scatter(x = index, y = vals, width=500, height=400).show()
    print()
for col in df.columns:
    if 'Year' in col:
        datestudy(df, col)
    elif df[col].dtype == object:
        catstudy(df, col)
    elif df[col].dtype == 'float64':
        ncstudy(df, col)
    elif df[col].dtype == 'int64':
        ndstudy(df, col)
**Insights for Uni_Variate Columns**
1. From_City

Goa, Chandigarh and Bengaluru are top travel origins, showing high outbound demand from major tier-1 and tier-2 cities.

2. Destination

Manali is the most popular destination, highlighting strong traveler interest in trekking.

3. Destination_Type

Cultural and coastal are dominate, showing a preference for traditions, nature.

4. Trip_Duration_Days

Most travelers prefer 4–7 day trips, making short vacations the most popular travel duration.

5. Budget_Range

Medium-budget packages are most preferred, indicating demand for affordable yet comfortable travel options.

6. Approx_Cost (₹)

Average trip cost is around ₹50K, confirming that travelers favor mid-range, value-for-money packages.

7. Accommodation_Type

Homestay and resorts are top choices, emphasizing comfort and convenience in accommodation preferences.

8. Transport_Mode

Train and car are the main transport modes, showing travelers prioritize speed and cost-efficiency.

9. Meal_Plan

Most travelers prefer breakfast or full-board -only plans for convenience and flexibility in dining.

10. Activity_Count

Trips typically include 3–4 activities, balancing relaxation with engagement.

11. Activity_Types

Wildlife and WaterSports experiences lead, reflecting travelers’ interest in exploration over adventure.

12. Season

Summer is the peak travel season, with significantly higher bookings than in summer.

13. Package_Type

Budget and Luxury packages dominate, showing a market leaning toward affordable excitement.

14. Recommended_For

Family and solo groups are the primary travelers, highlighting demand for group-friendly packages.
**Bi/Multi-Variate Analysis** - Study of Data between two/more columns
Bi/Multi-Variate Combo|Stats Measures
-----------|-----------
Numerical-Numerical|Correlation (-1 to +1)
Numerical-Categorical|Aggregation Functions (count, min, max, avg, sum)
Categorical-Categorical|FDT
- Correlation Coeffiecient Relation Categories
  - 0.75 to 1 - Strong Correlation
  - 0.50 to 0.75 - Moderate Correlation
  - <0.50 - Weak Correlation
- Visualizations

  - Pure Numerical : Relations: Scatter/Pairplots/Heatmaps

  - Pure Categorical : Composition: Pie/Stacked BarCharts/Sunburst Charts

  - Mixed: Composition : Pie/Barcharts/Sunburst

 - Apart from above combos if we can have Date & Locations , then we can have

   - Date: Trends Over time: LineCharts/Area Charts
   - Locations: GeoSpatial: Choropleth maps
**Selecting specific column combos from above to study the data**

Pure Numerical Columns|Mixed Columns|Pure Categorical Columns
----------------------|-------------|------------------------
Trip_Duration_Days vs Approx_Cost (₹)|Approx_Cost (₹) vs Package_Type|Package_Type vs Recommended_For
Activity_Count vs Approx_Cost (₹)|Trip_Duration_Days vs Destination_Type|Destination_Type vs Season



**Pure Numerical Columns**
- Descriptive Stats
   - Correlation Coefficient 
- Visualizations
  - Scatter/Heatmaps/Pairplots.
                  Activity_Count vs Approx_Cost (₹)
print("Checking if more activities increase cost...\n")

avg_cost_act = df.groupby('Activity_Count')['Approx_Cost (₹)'].mean().reset_index()
print(avg_cost_act)

plt.figure(figsize=(7,5))
sns.barplot(x='Activity_Count', y='Approx_Cost (₹)', data=avg_cost_act, palette='coolwarm')
plt.title("Activity Count vs Average Cost")
plt.xlabel("Number of Activities")
plt.ylabel("Average Cost (₹)")
plt.show()
**Insight**
- The more activities included in your trip, the higher the price — pick the number of activities based on your budget.
**Mixed Columns**
- Descriptive Stats
   - Aggregations : Count, Min, Max, Avg, Sum. 
- Visualizations
  - Pie/Bar Chart
                    1. Approx_Cost (₹) vs Package_Type
print("Average cost for each package type:\n")

avg_pkg = df.groupby('Package_Type')['Approx_Cost (₹)'].mean().sort_values(ascending=False)
print(avg_pkg)

plt.figure(figsize=(8,5))
sns.barplot(x=avg_pkg.index, y=avg_pkg.values, palette='magma')
plt.title("Average Cost by Package Type")
plt.xlabel("Package Type")
plt.ylabel("Average Cost (₹)")
plt.show()

**Insight**
- Budget packages are the most expensive, adventure packages are the cheapest — choose a package type that fits your wallet.
                2. Trip_Duration_Days vs Destination_Type
from scipy.stats import kruskal # type: ignore

# Kruskal–Wallis test (non-parametric)
groups = [g["Trip_Duration_Days"].values for _, g in df.groupby("Destination_Type")]
hstat, pval = kruskal(*groups)
print(f"Kruskal–Wallis H-statistic: {hstat:.3f}, p-value: {pval:.4f}")

# Visualization
plt.figure(figsize=(10,5))
sns.boxplot(x='Destination_Type', y='Trip_Duration_Days', data=df, palette='coolwarm')
plt.title("Trip Duration by Destination Type")
plt.xlabel("Destination Type")
plt.ylabel("Trip Duration (Days)")
plt.xticks(rotation=45)
plt.grid(True, linestyle='--', alpha=0.6)
plt.show()
**Insight**
- Hill Mountain,city, beach, backwater, desert and adventure spots need more days to enjoy fully, while historical, island, coastal, cultural, hill station trips can be shorter.
**Categorical Columns**
- Descriptive stats
  - FDT
- Visualizations
  - Sunburst
                        1. Package_Type vs Recommended_For
print("How different traveler types choose package types:\n")

count_table = pd.crosstab(df['Recommended_For'], df['Package_Type'])
print(count_table)

plt.figure(figsize=(8,5))
sns.heatmap(count_table, annot=True, fmt='d', cmap='YlGnBu')
plt.title("Traveler Type vs Package Type")
plt.xlabel("Package Type")
plt.ylabel("Traveler Type")
plt.show()
**Insight**
- Families, friends, and couples prefer different packages, but Budget will be the right type for each group.
                        2. Destination_Type vs Season
print("Season-wise preference for each destination type:\n")

count_table2 = pd.crosstab(df['Destination_Type'], df['Season'])
print(count_table2)

plt.figure(figsize=(9,5))
sns.heatmap(count_table2, annot=True, fmt='d', cmap='coolwarm')
plt.title("Destination Type vs Season")
plt.xlabel("Season")
plt.ylabel("Destination Type")
plt.show()
**Insight**
- Different destinations shine in different seasons — cultural are popular in all seasons.
**Overall Insights for Bi/Multi-Variate Columns**
- 1️. Trip Duration vs Cost
   - Trips that last longer usually cost more, so if you plan a short getaway, it will be cheaper.

- 2. Activity Count vs Cost
   - The more activities included in your trip, the higher the price — pick the number of activities based on your budget.

- 3. Cost vs Package Type
   - Luxury packages are the most expensive, budget packages are the cheapest — choose a package type that fits your wallet.

- 4️. Trip Duration vs Destination Type
   - Hill stations and adventure spots need more days to enjoy fully, while city or beach trips can be shorter.

- 5️. Package Type vs Recommended For
   - Families, friends, and couples prefer different packages — travel companies can suggest the right type for each group.

- 6️. Destination Type vs Season
   - Different destinations shine in different seasons — beaches are popular in winter, hills in summer, and cities all year round.
**3. Missing Values & Outliers Handling**<a id='MVOH'>
    
[Back to Top](#ToC)

**3.1 Missing Values Identification & Handling**
* Empty values or any data point which is not belongs to column.
* Identify Missing Values
    - Check for Standard & Non-Standard nan values 
* Handle the Missing Values
    - Drop (Row, Column)
    - Replace (MCT, Imputation, etc...)
* Some ML Algorithms will not accept missing data.
**a) Identification**
- Using pandas dataframe **isnull()** function
**i) Row Wise Na Count**
data.isnull().sum(axis=1)
**ii) Column Wise Na Count**
data.isnull().sum()
- We can proceed to the next step, because there are No missing values.
**3.2 Outliers Handling**
* For a Numeric Col, if we got extreme values, then these are considered as outliers according to stats.
* Outlier can be lower or higher values
* Outliers will effect mean and std stats params
* Some of ML Algorithms are sensitive to Outliers
# Taking user defined module

import plotly.express as px # type: ignore

def outlier_detect(df):
    cols = []
    for col in df.describe().columns:
        print("Column:",col)
        print("------------------------------------------------")
        print("Boxplot For Outlier Identification:")
        px.box(df[col], orientation='h', width=600, height=300, ).show()
        print()
        Q1 = df.describe().at['25%',col]
        Q3 = df.describe().at['75%',col]
        IQR = Q3 - Q1
        lowerbound = Q1 - 1.5 * IQR
        upperbound = Q3 + 1.5 * IQR
        
        print("********* Outlier Data Points *******")
        print()
        lowerout = []
        upperout = []

        for val in df[col]:
            if val<lowerbound:
                if val not in lowerout:
                    lowerout.append(val)
            elif val>upperbound:
                if val not in upperout:
                    upperout.append(val)

        lowerout.sort()
        upperout.sort()

        print("Lower Outliers:")
        print(lowerout)
        print()
        print()
        print("Upper Outliers:")
        print(upperout)
        print()
        print("===============================================")
        print()
        
        if lowerout!=[] or upperout!=[]:
            cols.append(col)
      
    return cols
        
def outlier_replacement(df, cols):
    for col in cols:
        print("Column:",col)
        print("------------------------------------------------")
        Q1 = df.describe().at['25%',col]
        Q3 = df.describe().at['75%',col]
        IQR = Q3 - Q1
        LTV = Q1 - 1.5 * IQR
        UTV = Q3 + 1.5 * IQR
        
        # replacement vals (any one of the below)
        
        # 1. Median
        median = df[col].median()
        
        # 2. Ltv, Utv
        low_bound = LTV
        high_bound = UTV
        
        # 3. 5th & 95th (Suggested)
        fifth = df[col].quantile(0.05)
        ninetyfifth = df[col].quantile(0.95)

        print("Replacing Outliers with 5th percentile for lower Outliers, 95th percentile for Upper Outliers....")
        print("Adjust the module code for any other replacements.........")
        print()
        
        # mask method is used to replace the values
        df[col] = df[col].mask(df[col]<LTV, round(fifth)) # replacing the lower outlier with 5th percentile value
        df[col] = df[col].mask(df[col]>UTV, round(ninetyfifth)) # replacing the outlier with 95th percentile value
outcols = outlier_detect(data)
- We don't have any Outliers.
**4.2.2 Feature Modification(Data Pre-Processing)**

**Encoding :** Converting all Categorical columns to Numerical columns.
from sklearn.preprocessing import OneHotEncoder, MinMaxScaler # type: ignore
from sklearn.metrics.pairwise import cosine_similarity # type: ignore
from IPython.display import display # type: ignore
df.columns = df.columns.str.strip()
df.columns
feature_cols = [
    'Destination_Type',
    'Trip_Duration_Days',
    'Approx_Cost (₹)',
    'Accommodation_Type',
    'Transport_Mode',
    'Season',
    'Package_Type'
]
df[feature_cols] = df[feature_cols].fillna('Unknown')
numeric_features = ['Trip_Duration_Days', 'Approx_Cost (₹)']
categorical_features = [c for c in feature_cols if c not in numeric_features]
categorical_features
ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
encoded_cats = ohe.fit_transform(df[categorical_features])
encoded_cat_df = pd.DataFrame(encoded_cats, columns=ohe.get_feature_names_out(categorical_features))
encoded_cat_df
scaler = MinMaxScaler()
scaled_nums = scaler.fit_transform(df[numeric_features])
scaled_num_df = pd.DataFrame(scaled_nums, columns=numeric_features)
scaled_num_df
processed_features = pd.concat([encoded_cat_df, scaled_num_df], axis=1)
processed_features
weights = {
    'Destination_Type': 0.4,
    'Trip_Duration_Days': 0.2,
    'Approx_Cost (₹)': 0.25,
    'Accommodation_Type': 0.05,
    'Transport_Mode': 0.05,
    'Season': 0.025,
    'Package_Type': 0.025
}
for col in ohe.get_feature_names_out():
    for key in weights:
        if col.startswith(key):
            processed_features[col] *= weights[key]
for num_col in numeric_features:
    processed_features[num_col] *= weights[num_col]
processed_features[num_col]
def get_destinations_by_city(from_city):
    """Return all unique destinations from a given From_City."""
    return sorted(df[df['From_City'] == from_city]['Destination'].unique().tolist())
def get_destination_types(from_city, destination):
    """Return all unique destination types for the selected city & destination."""
    return sorted(df[(df['From_City'] == from_city) & (df['Destination'] == destination)]['Destination_Type'].unique().tolist())
def get_reference_vector(destination_type, duration, approx_cost):
    """Create reference vector from user inputs."""
    temp = pd.DataFrame([['Unknown'] * len(categorical_features) + [0, 0]],
                        columns=categorical_features + numeric_features)
    temp.loc[0, 'Destination_Type'] = destination_type
    temp.loc[0, 'Trip_Duration_Days'] = duration
    temp.loc[0, 'Approx_Cost (₹)'] = approx_cost

    temp_encoded = ohe.transform(temp[categorical_features])
    temp_encoded_df = pd.DataFrame(temp_encoded, columns=ohe.get_feature_names_out(categorical_features))

    temp_scaled = scaler.transform(temp[numeric_features])
    temp_scaled_df = pd.DataFrame(temp_scaled, columns=numeric_features)

    temp_vector = pd.concat([temp_encoded_df, temp_scaled_df], axis=1)

    for col in ohe.get_feature_names_out():
        for key in weights:
            if col.startswith(key):
                temp_vector[col] *= weights[key]
    for num_col in numeric_features:
        temp_vector[num_col] *= weights[num_col]

    return temp_vector.values
def recommend_packages(from_city, destination, destination_type, duration, approx_cost, top_n=5):
    """Recommend top packages using cosine similarity."""
    filtered_df = df[(df['From_City'] == from_city) & 
                     (df['Destination'] == destination) &
                     (df['Destination_Type'] == destination_type)]
    
    if filtered_df.empty:
        print("⚠ No packages found for this route and destination type.")
        return

    filtered_features = processed_features.loc[filtered_df.index]
    ref_vector = get_reference_vector(destination_type, duration, approx_cost)

    sim_scores = cosine_similarity(ref_vector, filtered_features)[0]
    top_idx = np.argsort(sim_scores)[::-1][:top_n]

    top_packages = filtered_df.iloc[top_idx].copy()
    top_packages['Similarity_Score'] = sim_scores[top_idx]

    print(f"\n🎯 Top {top_n} Recommended Packages for {from_city} → {destination} ({destination_type}):\n")
    display(top_packages[['From_City','Destination','Destination_Type','Package_Type',
                           'Trip_Duration_Days','Approx_Cost (₹)',
                           'Accommodation_Type','Transport_Mode','Season','Similarity_Score']])

from_city = input("Enter From_City: ")

available_destinations = get_destinations_by_city(from_city)
if not available_destinations:
    print(f"❌ No destinations found for {from_city}")
else:
    print(f"🌍 Available Destinations from {from_city}: {available_destinations}")
    destination = input("Enter Destination: ")

    available_types = get_destination_types(from_city, destination)
    if not available_types:
        print(f"❌ No destination types found for {destination}")
    else:
        print(f"🏖 Available Destination Types for {destination}: {available_types}")
        destination_type = input("Enter Destination Type: ")

        trip_duration = int(input("Enter Trip Duration (days): "))
        approx_cost = int(input("Enter Approx Cost (₹): "))

        recommend_packages(from_city, destination, destination_type, trip_duration, approx_cost, top_n=5)
